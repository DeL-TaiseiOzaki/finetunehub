model:
  name_or_path: "llm-jp/llm-jp-3-13b"
  tokenizer_name: null
  cache_dir: null

dataset:
  load_from: "huggingface"
  name: "DeL-TaiseiOzaki/Tengentoppa-sft-v1.0"
  data_files:
    train: "data/dataset_train.json"
  cache_dir: null
  batch_size: 1000
  processing:
    num_proc: 4
    cache_enabled: true

training:
  output_dir: "./llm-jp-ft-output"
  num_train_epochs: 1
  per_device_train_batch_size: 2
  block_size: 2048
  learning_rate: 1e-5
  seed: 42
  fp16: false
  bf16: true
  optim: "adamw_torch"
  gradient_checkpointing: true
  ddp: true
  gradient_accumulation_steps: 16

prompts:
  use_custom_prompt: true
  use_chat_template: true
  default_system_prompt: "あなたは誠実で優秀な日本人のアシスタントです。タスクを説明する指示と、さらなる文脈を提供する入力を元に、要求を適切に完了する応答を書きなさい。\n"
  user_prompt: ""

logging:
  logging_dir: "./logs"
  logging_steps: 100
  use_wandb: true