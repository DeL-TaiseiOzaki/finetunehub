2024-09-30 14:37:12,762 - INFO - __main__ - ファインチューニングプロセスを開始します
2024-09-30 14:40:45,075 - INFO - __main__ - ファインチューニングプロセスを開始します
2024-09-30 14:40:47,486 - INFO - __main__ - elyza/Llama-3-ELYZA-JP-8B のトークナイザを読み込んでいます
2024-09-30 14:40:47,773 - INFO - __main__ - elyza/Llama-3-ELYZA-JP-8B のモデルを読み込んでいます
2024-09-30 14:40:48,129 - INFO - accelerate.utils.modeling - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2024-09-30 14:40:51,398 - INFO - __main__ - MKJ-TOE/detect_missinfo_instruction_ja のデータセットを読み込んでいます
2024-09-30 14:40:52,211 - INFO - __main__ - データセットをトークナイズしています
2024-09-30 17:04:07,756 - INFO - __main__ - ファインチューニングプロセスを開始します
2024-09-30 17:04:10,174 - INFO - __main__ - elyza/Llama-3-ELYZA-JP-8B のトークナイザを読み込んでいます
2024-09-30 17:04:10,468 - INFO - __main__ - elyza/Llama-3-ELYZA-JP-8B のモデルを読み込んでいます
2024-09-30 17:04:10,802 - INFO - accelerate.utils.modeling - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2024-09-30 17:04:14,098 - INFO - __main__ - MKJ-TOE/detect_missinfo_instruction_ja のデータセットを読み込んでいます
2024-09-30 17:04:14,774 - INFO - __main__ - データセットをトークナイズしています
2024-09-30 17:41:33,270 - INFO - __main__ - ファインチューニングプロセスを開始します
2024-09-30 17:41:35,687 - INFO - __main__ - elyza/Llama-3-ELYZA-JP-8B のトークナイザを読み込んでいます
2024-09-30 17:41:37,325 - INFO - __main__ - elyza/Llama-3-ELYZA-JP-8B のモデルを読み込んでいます
2024-09-30 17:41:37,780 - INFO - accelerate.utils.modeling - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2024-09-30 17:41:41,119 - INFO - __main__ - MKJ-TOE/detect_missinfo_instruction_ja のデータセットを読み込んでいます
2024-09-30 17:41:41,986 - INFO - __main__ - データセットをトークナイズしています
2024-09-30 17:41:43,454 - INFO - __main__ - トレーニングを開始します
2024-09-30 17:47:34,637 - INFO - __main__ - ファインチューニングプロセスを開始します
2024-09-30 17:47:37,025 - INFO - __main__ - elyza/Llama-3-ELYZA-JP-8B のトークナイザを読み込んでいます
2024-09-30 17:47:37,300 - INFO - __main__ - elyza/Llama-3-ELYZA-JP-8B のモデルを読み込んでいます
2024-09-30 17:47:37,641 - INFO - accelerate.utils.modeling - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2024-09-30 17:47:40,910 - INFO - __main__ - MKJ-TOE/detect_missinfo_instruction_ja のデータセットを読み込んでいます
2024-09-30 17:47:41,463 - INFO - __main__ - データセットをトークナイズしています
2024-09-30 17:47:41,826 - INFO - __main__ - トレーニングを開始します
2024-09-30 17:56:47,512 - INFO - __main__ - ファインチューニングプロセスを開始します
2024-09-30 17:56:49,879 - INFO - __main__ - elyza/Llama-3-ELYZA-JP-8B のトークナイザを読み込んでいます
2024-09-30 17:56:50,191 - INFO - __main__ - elyza/Llama-3-ELYZA-JP-8B のモデルを読み込んでいます
2024-09-30 17:56:50,542 - INFO - accelerate.utils.modeling - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2024-09-30 17:56:53,907 - INFO - __main__ - MKJ-TOE/detect_missinfo_instruction_ja のデータセットを読み込んでいます
2024-09-30 17:56:54,555 - INFO - __main__ - データセットをトークナイズしています
2024-09-30 17:56:54,700 - INFO - __main__ - トレーニングを開始します
2024-09-30 18:03:08,140 - INFO - __main__ - ファインチューニングプロセスを開始します
2024-09-30 18:03:10,570 - INFO - __main__ - elyza/Llama-3-ELYZA-JP-8B のトークナイザを読み込んでいます
2024-09-30 18:03:10,848 - INFO - __main__ - elyza/Llama-3-ELYZA-JP-8B のモデルを読み込んでいます
2024-09-30 18:03:11,192 - INFO - accelerate.utils.modeling - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2024-09-30 18:03:14,245 - INFO - __main__ - MKJ-TOE/detect_missinfo_instruction_ja のデータセットを読み込んでいます
2024-09-30 18:03:14,853 - INFO - __main__ - データセットをトークナイズしています
2024-09-30 18:03:14,996 - INFO - __main__ - トレーニングを開始します
2024-09-30 18:05:01,247 - INFO - __main__ - ファインチューニングプロセスを開始します
2024-09-30 18:05:03,629 - INFO - __main__ - elyza/Llama-3-ELYZA-JP-8B のトークナイザを読み込んでいます
2024-09-30 18:05:03,932 - INFO - __main__ - elyza/Llama-3-ELYZA-JP-8B のモデルを読み込んでいます
2024-09-30 18:05:04,271 - INFO - accelerate.utils.modeling - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2024-09-30 18:05:07,338 - INFO - __main__ - MKJ-TOE/detect_missinfo_instruction_ja のデータセットを読み込んでいます
2024-09-30 18:05:07,923 - INFO - __main__ - データセットをトークナイズしています
2024-09-30 18:05:08,061 - INFO - __main__ - トレーニングを開始します
2024-09-30 18:06:17,026 - INFO - __main__ - ファインチューニングプロセスを開始します
2024-09-30 18:06:17,027 - INFO - __main__ - elyza/Llama-3-ELYZA-JP-8B のトークナイザを読み込んでいます
2024-09-30 18:06:17,315 - INFO - __main__ - elyza/Llama-3-ELYZA-JP-8B のモデルを読み込んでいます
2024-09-30 18:06:17,671 - INFO - accelerate.utils.modeling - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2024-09-30 18:06:20,746 - INFO - __main__ - MKJ-TOE/detect_missinfo_instruction_ja のデータセットを読み込んでいます
2024-09-30 18:06:21,266 - INFO - __main__ - データセットをトークナイズしています
2024-09-30 18:06:21,412 - INFO - __main__ - トレーニングを開始します
2024-09-30 18:07:05,067 - INFO - __main__ - ファインチューニングプロセスを開始します
2024-09-30 18:07:05,068 - INFO - __main__ - elyza/Llama-3-ELYZA-JP-8B のトークナイザを読み込んでいます
2024-09-30 18:07:05,369 - INFO - __main__ - elyza/Llama-3-ELYZA-JP-8B のモデルを読み込んでいます
2024-09-30 18:07:05,707 - INFO - accelerate.utils.modeling - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2024-09-30 18:07:08,835 - INFO - __main__ - LoRAの設定を行っています
2024-09-30 18:07:09,132 - INFO - __main__ - MKJ-TOE/detect_missinfo_instruction_ja のデータセットを読み込んでいます
2024-09-30 18:07:09,710 - INFO - __main__ - データセットをトークナイズしています
2024-09-30 18:07:09,858 - INFO - __main__ - トレーニングを開始します
2024-09-30 18:14:17,716 - INFO - __main__ - ファインチューニング済みモデルを保存しています
2024-09-30 18:23:09,690 - INFO - __main__ - ファインチューニングプロセスを開始します
2024-09-30 18:23:09,691 - INFO - __main__ - elyza/Llama-3-ELYZA-JP-8B のトークナイザを読み込んでいます
2024-09-30 18:23:10,009 - INFO - __main__ - elyza/Llama-3-ELYZA-JP-8B のモデルを読み込んでいます
2024-09-30 18:23:10,499 - INFO - accelerate.utils.modeling - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2024-09-30 18:23:13,793 - INFO - __main__ - MKJ-TOE/detect_missinfo_instruction_ja のデータセットを読み込んでいます
2024-09-30 18:23:14,349 - INFO - __main__ - データセットをトークナイズしています
2024-09-30 18:23:14,499 - INFO - __main__ - トレーニングを開始します
2024-09-30 18:30:03,100 - INFO - __main__ - ファインチューニングプロセスを開始します
2024-09-30 18:30:03,100 - INFO - __main__ - elyza/Llama-3-ELYZA-JP-8B のトークナイザを読み込んでいます
2024-09-30 18:30:03,404 - INFO - __main__ - elyza/Llama-3-ELYZA-JP-8B のモデルを読み込んでいます
2024-09-30 18:30:03,746 - INFO - accelerate.utils.modeling - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2024-09-30 18:30:06,761 - INFO - __main__ - MKJ-TOE/detect_missinfo_instruction_ja のデータセットを読み込んでいます
2024-09-30 18:30:07,334 - INFO - __main__ - データセットをトークナイズしています
2024-09-30 18:30:07,472 - INFO - __main__ - トレーニングを開始します
2024-09-30 18:30:23,994 - INFO - __main__ - ファインチューニングプロセスを開始します
2024-09-30 18:30:23,994 - INFO - __main__ - elyza/Llama-3-ELYZA-JP-8B のトークナイザを読み込んでいます
2024-09-30 18:30:24,300 - INFO - __main__ - elyza/Llama-3-ELYZA-JP-8B のモデルを読み込んでいます
2024-09-30 18:30:24,636 - INFO - accelerate.utils.modeling - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2024-09-30 18:30:27,666 - INFO - __main__ - MKJ-TOE/detect_missinfo_instruction_ja のデータセットを読み込んでいます
2024-09-30 18:30:28,186 - INFO - __main__ - データセットをトークナイズしています
2024-09-30 18:30:28,328 - INFO - __main__ - トレーニングを開始します
2024-09-30 18:32:50,649 - INFO - __main__ - ファインチューニングプロセスを開始します
2024-09-30 18:32:50,649 - INFO - __main__ - elyza/Llama-3-ELYZA-JP-8B のトークナイザを読み込んでいます
2024-09-30 18:32:50,941 - INFO - __main__ - elyza/Llama-3-ELYZA-JP-8B のモデルを読み込んでいます
2024-09-30 18:32:51,305 - INFO - accelerate.utils.modeling - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2024-09-30 18:32:56,018 - INFO - __main__ - MKJ-TOE/detect_missinfo_instruction_ja のデータセットを読み込んでいます
2024-09-30 18:32:56,503 - INFO - __main__ - データセットをトークナイズしています
2024-09-30 18:32:56,640 - INFO - __main__ - トレーニングを開始します
2024-09-30 18:33:20,379 - INFO - __main__ - ファインチューニングプロセスを開始します
2024-09-30 18:33:20,379 - INFO - __main__ - elyza/Llama-3-ELYZA-JP-8B のトークナイザを読み込んでいます
2024-09-30 18:33:20,670 - INFO - __main__ - elyza/Llama-3-ELYZA-JP-8B のモデルを読み込んでいます
2024-09-30 18:33:21,014 - INFO - accelerate.utils.modeling - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2024-09-30 18:33:25,781 - INFO - __main__ - MKJ-TOE/detect_missinfo_instruction_ja のデータセットを読み込んでいます
2024-09-30 18:33:26,319 - INFO - __main__ - データセットをトークナイズしています
2024-09-30 18:33:26,453 - INFO - __main__ - トレーニングを開始します
2024-09-30 18:35:00,903 - INFO - __main__ - ファインチューニングプロセスを開始します
2024-09-30 18:35:00,903 - INFO - __main__ - elyza/Llama-3-ELYZA-JP-8B のトークナイザを読み込んでいます
2024-09-30 18:35:01,301 - INFO - __main__ - elyza/Llama-3-ELYZA-JP-8B のモデルを読み込んでいます
2024-09-30 18:35:01,664 - INFO - accelerate.utils.modeling - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2024-09-30 18:35:05,039 - INFO - __main__ - MKJ-TOE/detect_missinfo_instruction_ja のデータセットを読み込んでいます
2024-09-30 18:35:05,731 - INFO - __main__ - データセットをトークナイズしています
2024-09-30 18:35:05,857 - INFO - __main__ - トレーニングを開始します
2024-10-01 01:21:04,400 - INFO - __main__ - ファインチューニングプロセスを開始します
2024-10-01 01:21:04,401 - INFO - __main__ - elyza/Llama-3-ELYZA-JP-8B のトークナイザを読み込んでいます
2024-10-01 01:21:04,699 - INFO - __main__ - elyza/Llama-3-ELYZA-JP-8B のモデルを読み込んでいます
2024-10-01 01:21:05,036 - INFO - accelerate.utils.modeling - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2024-10-01 01:21:09,791 - INFO - __main__ - MKJ-TOE/detect_missinfo_instruction_ja のデータセットを読み込んでいます
2024-10-01 01:21:10,812 - INFO - __main__ - データセットをトークナイズしています
2024-10-01 01:21:44,016 - INFO - __main__ - ファインチューニングプロセスを開始します
2024-10-01 01:21:44,017 - INFO - __main__ - elyza/Llama-3-ELYZA-JP-8B のトークナイザを読み込んでいます
2024-10-01 01:21:44,288 - INFO - __main__ - elyza/Llama-3-ELYZA-JP-8B のモデルを読み込んでいます
2024-10-01 01:21:44,626 - INFO - accelerate.utils.modeling - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2024-10-01 01:21:49,424 - INFO - __main__ - MKJ-TOE/detect_missinfo_instruction_ja のデータセットを読み込んでいます
2024-10-01 01:21:49,978 - INFO - __main__ - データセットをトークナイズしています
2024-10-01 01:45:38,303 - INFO - __main__ - ファインチューニングプロセスを開始します
2024-10-01 01:45:38,304 - INFO - __main__ - elyza/Llama-3-ELYZA-JP-8B のトークナイザを読み込んでいます
2024-10-01 01:45:38,603 - INFO - __main__ - elyza/Llama-3-ELYZA-JP-8B のモデルを読み込んでいます
2024-10-01 01:45:38,971 - INFO - accelerate.utils.modeling - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2024-10-01 01:45:43,722 - INFO - __main__ - MKJ-TOE/detect_missinfo_instruction_ja のデータセットを読み込んでいます
2024-10-01 01:45:44,357 - INFO - __main__ - データセットをトークナイズしています
2024-10-01 01:48:06,864 - INFO - __main__ - ファインチューニングプロセスを開始します
2024-10-01 01:48:06,865 - INFO - __main__ - elyza/Llama-3-ELYZA-JP-8B のトークナイザを読み込んでいます
2024-10-01 01:48:07,223 - INFO - __main__ - elyza/Llama-3-ELYZA-JP-8B のモデルを読み込んでいます
2024-10-01 01:48:07,573 - INFO - accelerate.utils.modeling - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2024-10-01 01:48:10,678 - INFO - __main__ - MKJ-TOE/detect_missinfo_instruction_ja のデータセットを読み込んでいます
2024-10-01 01:48:11,221 - INFO - __main__ - データセットをトークナイズしています
2024-10-01 02:08:43,184 - INFO - __main__ - ファインチューニングプロセスを開始します
2024-10-01 02:08:43,184 - INFO - __main__ - elyza/Llama-3-ELYZA-JP-8B のトークナイザを読み込んでいます
2024-10-01 02:08:43,476 - INFO - __main__ - elyza/Llama-3-ELYZA-JP-8B のモデルを読み込んでいます
2024-10-01 02:08:43,831 - INFO - accelerate.utils.modeling - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2024-10-01 02:08:46,939 - INFO - __main__ - MKJ-TOE/detect_missinfo_instruction_ja のデータセットを読み込んでいます
2024-10-01 02:08:47,904 - INFO - __main__ - データセットをトークナイズしています
2024-10-01 02:08:50,063 - INFO - __main__ - トレーニングを開始します
2024-10-01 02:17:09,014 - INFO - __main__ - ファインチューニングプロセスを開始します
2024-10-01 02:17:09,015 - INFO - __main__ - elyza/Llama-3-ELYZA-JP-8B のトークナイザを読み込んでいます
2024-10-01 02:17:09,316 - INFO - __main__ - elyza/Llama-3-ELYZA-JP-8B のモデルを読み込んでいます
2024-10-01 02:17:09,728 - INFO - accelerate.utils.modeling - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2024-10-01 02:18:55,197 - INFO - __main__ - ファインチューニングプロセスを開始します
2024-10-01 02:18:55,197 - INFO - __main__ - elyza/Llama-3-ELYZA-JP-8B のトークナイザを読み込んでいます
2024-10-01 02:18:55,488 - INFO - __main__ - elyza/Llama-3-ELYZA-JP-8B のモデルを読み込んでいます
2024-10-01 02:18:55,831 - INFO - accelerate.utils.modeling - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2024-10-01 02:19:00,982 - INFO - __main__ - MKJ-TOE/detect_missinfo_instruction_ja のデータセットを読み込んでいます
2024-10-01 02:19:01,521 - INFO - __main__ - データセットをトークナイズしています
2024-10-01 02:29:16,442 - INFO - __main__ - ファインチューニングプロセスを開始します
2024-10-01 02:29:16,442 - INFO - __main__ - elyza/Llama-3-ELYZA-JP-8B のトークナイザを読み込んでいます
2024-10-01 02:29:16,722 - INFO - __main__ - elyza/Llama-3-ELYZA-JP-8B のモデルを読み込んでいます
2024-10-01 02:29:17,050 - INFO - accelerate.utils.modeling - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2024-10-01 02:29:20,087 - INFO - __main__ - MKJ-TOE/detect_missinfo_instruction_ja のデータセットを読み込んでいます
2024-10-01 02:29:20,663 - INFO - __main__ - データセットをトークナイズしています
2024-10-01 02:29:22,890 - INFO - __main__ - トレーニングを開始します
2024-10-01 04:59:17,310 - INFO - __main__ - ファインチューニングプロセスを開始します
2024-10-01 04:59:17,310 - INFO - __main__ - elyza/Llama-3-ELYZA-JP-8B のトークナイザを読み込んでいます
2024-10-01 04:59:17,595 - INFO - __main__ - elyza/Llama-3-ELYZA-JP-8B のモデルを読み込んでいます
2024-10-01 04:59:17,949 - INFO - accelerate.utils.modeling - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2024-10-01 04:59:20,982 - INFO - __main__ - データセットを読み込んでいます (source: local)
2024-10-01 04:59:21,090 - INFO - __main__ - データセットをトークナイズしています
2024-10-01 04:59:23,211 - INFO - __main__ - トレーニングを開始します
2024-11-24 05:22:27,517 - INFO - __main__ - ファインチューニングプロセスを開始します
2024-11-24 05:22:54,744 - INFO - __main__ - ファインチューニングプロセスを開始します
2024-11-24 05:23:33,569 - INFO - __main__ - google/gemma-2-9b のトークナイザを読み込んでいます
2024-11-24 05:23:36,534 - INFO - __main__ - google/gemma-2-9b のモデルを読み込んでいます
2024-11-24 06:22:49,026 - INFO - accelerate.utils.modeling - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2024-11-24 06:22:56,173 - INFO - __main__ - データセットを読み込んでいます (source: huggingface)
2024-11-24 06:24:39,068 - INFO - __main__ - データセットをトークナイズしています
2024-11-24 08:51:18,836 - INFO - __main__ - ファインチューニングプロセスを開始します
2024-11-24 08:51:20,392 - INFO - __main__ - google/gemma-2-9b のトークナイザを読み込んでいます
2024-11-24 08:51:20,970 - INFO - __main__ - google/gemma-2-9b のモデルを読み込んでいます
2024-11-24 08:51:21,323 - INFO - accelerate.utils.modeling - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2024-11-24 08:51:28,931 - INFO - __main__ - データセットを読み込んでいます (source: huggingface)
2024-11-24 08:51:29,936 - INFO - __main__ - データセットをトークナイズしています
2024-11-24 08:55:42,834 - INFO - __main__ - ファインチューニングプロセスを開始します
2024-11-24 08:55:44,339 - INFO - __main__ - google/gemma-2-9b のトークナイザを読み込んでいます
2024-11-24 08:55:44,887 - INFO - __main__ - google/gemma-2-9b のモデルを読み込んでいます
2024-11-24 08:55:45,248 - INFO - accelerate.utils.modeling - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2024-11-24 08:55:50,419 - INFO - __main__ - データセットを読み込んでいます (source: huggingface)
2024-11-24 08:55:51,003 - INFO - __main__ - データセットをトークナイズしています
2024-11-24 08:56:12,843 - INFO - __main__ - ファインチューニングプロセスを開始します
2024-11-24 08:56:14,170 - INFO - __main__ - google/gemma-2-9b のトークナイザを読み込んでいます
2024-11-24 08:56:14,751 - INFO - __main__ - google/gemma-2-9b のモデルを読み込んでいます
2024-11-24 08:56:15,082 - INFO - accelerate.utils.modeling - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2024-11-24 08:56:20,293 - INFO - __main__ - データセットを読み込んでいます (source: huggingface)
2024-11-24 08:56:21,140 - INFO - __main__ - データセットをトークナイズしています
2024-11-24 08:58:43,362 - INFO - __main__ - ファインチューニングプロセスを開始します
2024-11-24 08:58:44,729 - INFO - __main__ - google/gemma-2-9b のトークナイザを読み込んでいます
2024-11-24 08:58:45,301 - INFO - __main__ - google/gemma-2-9b のモデルを読み込んでいます
2024-11-24 08:58:45,666 - INFO - accelerate.utils.modeling - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2024-11-24 08:58:51,027 - INFO - __main__ - データセットを読み込んでいます (source: huggingface)
2024-11-24 08:58:51,925 - INFO - __main__ - データセットをトークナイズしています
2024-11-24 09:12:24,564 - INFO - __main__ - ファインチューニングプロセスを開始します
2024-11-24 09:12:25,884 - INFO - __main__ - google/gemma-2-9b のトークナイザを読み込んでいます
2024-11-24 09:12:26,479 - INFO - __main__ - google/gemma-2-9b のモデルを読み込んでいます
2024-11-24 09:12:26,840 - INFO - accelerate.utils.modeling - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2024-11-24 09:12:32,190 - INFO - __main__ - データセットを読み込んでいます (source: huggingface)
2024-11-24 09:12:33,130 - INFO - __main__ - データセットをトークナイズしています
2024-11-24 09:12:33,401 - INFO - __main__ - データセットのトークナイズを開始します
2024-11-24 09:19:10,975 - INFO - __main__ - ファインチューニングプロセスを開始します
2024-11-24 09:19:12,273 - INFO - __main__ - google/gemma-2-9b のトークナイザを読み込んでいます
2024-11-24 09:19:12,947 - INFO - __main__ - google/gemma-2-9b のモデルを読み込んでいます
2024-11-24 09:19:13,315 - INFO - accelerate.utils.modeling - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2024-11-24 09:19:18,672 - INFO - __main__ - データセットを読み込んでいます (source: huggingface)
2024-11-24 09:19:19,267 - INFO - __main__ - データセットをトークナイズしています
2024-11-24 09:19:19,512 - INFO - __main__ - データセットのトークナイズを開始します
2024-11-24 09:25:56,715 - INFO - __main__ - ファインチューニングプロセスを開始します
2024-11-24 09:25:58,135 - INFO - __main__ - google/gemma-2-9b のトークナイザを読み込んでいます
2024-11-24 09:25:58,763 - INFO - __main__ - google/gemma-2-9b のモデルを読み込んでいます
2024-11-24 09:25:59,140 - INFO - accelerate.utils.modeling - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2024-11-24 09:26:04,526 - INFO - __main__ - データセットを読み込んでいます (source: huggingface)
2024-11-24 09:26:05,125 - INFO - __main__ - データセットをトークナイズしています
2024-11-24 09:59:17,963 - INFO - __main__ - ファインチューニングプロセスを開始します
2024-11-24 09:59:19,455 - INFO - __main__ - google/gemma-2-9b のトークナイザを読み込んでいます
2024-11-24 09:59:20,019 - INFO - __main__ - google/gemma-2-9b のモデルを読み込んでいます
2024-11-24 09:59:20,372 - INFO - accelerate.utils.modeling - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2024-11-24 09:59:25,526 - INFO - __main__ - データセットを読み込んでいます (source: huggingface)
2024-11-24 09:59:26,231 - INFO - __main__ - データセットをトークナイズしています
2024-11-24 10:05:58,174 - INFO - __main__ - ファインチューニングプロセスを開始します
2024-11-24 10:05:59,539 - INFO - __main__ - google/gemma-2-9b のトークナイザを読み込んでいます
2024-11-24 10:06:00,112 - INFO - __main__ - google/gemma-2-9b のモデルを読み込んでいます
2024-11-24 10:06:00,504 - INFO - accelerate.utils.modeling - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2024-11-24 10:06:06,051 - INFO - __main__ - データセットを読み込んでいます (source: huggingface)
2024-11-24 10:06:06,674 - INFO - __main__ - デフォルトのチャットテンプレートを設定します
2024-11-24 10:06:06,675 - INFO - __main__ - データセットをトークナイズしています
2024-11-24 10:07:06,217 - INFO - __main__ - ファインチューニングプロセスを開始します
2024-11-24 10:07:07,625 - INFO - __main__ - google/gemma-2-9b のトークナイザを読み込んでいます
2024-11-24 10:07:08,185 - INFO - __main__ - google/gemma-2-9b のモデルを読み込んでいます
2024-11-24 10:07:08,564 - INFO - accelerate.utils.modeling - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2024-11-24 10:07:14,117 - INFO - __main__ - データセットを読み込んでいます (source: huggingface)
2024-11-24 10:07:14,790 - INFO - __main__ - デフォルトのチャットテンプレートを設定します
2024-11-24 10:07:14,790 - INFO - __main__ - データセットをトークナイズしています
2024-11-24 10:12:39,946 - INFO - __main__ - トレーニングを開始します
2024-11-24 11:20:22,479 - INFO - __main__ - ファインチューニングプロセスを開始します
2024-11-24 11:20:23,852 - INFO - __main__ - google/gemma-2-9b のトークナイザを読み込んでいます
2024-11-24 11:20:24,377 - INFO - __main__ - google/gemma-2-9b のモデルを読み込んでいます
2024-11-24 11:20:24,748 - INFO - accelerate.utils.modeling - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2024-11-24 11:20:58,534 - INFO - __main__ - ファインチューニングプロセスを開始します
2024-11-24 11:20:59,852 - INFO - __main__ - google/gemma-2-9b のトークナイザを読み込んでいます
2024-11-24 11:21:00,417 - INFO - __main__ - google/gemma-2-9b のモデルを読み込んでいます
2024-11-24 11:21:00,784 - INFO - accelerate.utils.modeling - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2024-11-24 11:21:06,489 - INFO - __main__ - データセットを読み込んでいます (source: huggingface)
2024-11-24 11:21:07,127 - INFO - __main__ - デフォルトのチャットテンプレートを設定します
2024-11-24 11:21:07,127 - INFO - __main__ - データセットをトークナイズしています
2024-11-24 11:22:21,853 - INFO - __main__ - ファインチューニングプロセスを開始します
2024-11-24 11:22:23,294 - INFO - __main__ - google/gemma-2-9b のトークナイザを読み込んでいます
2024-11-24 11:22:23,887 - INFO - __main__ - google/gemma-2-9b のモデルを読み込んでいます
2024-11-24 11:22:24,236 - INFO - accelerate.utils.modeling - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2024-11-24 11:22:30,049 - INFO - __main__ - LoRAの設定を行っています
2024-11-24 11:22:30,617 - INFO - __main__ - データセットを読み込んでいます (source: huggingface)
2024-11-24 11:22:31,230 - INFO - __main__ - デフォルトのチャットテンプレートを設定します
2024-11-24 11:22:31,230 - INFO - __main__ - データセットをトークナイズしています
2024-11-24 11:22:31,776 - INFO - __main__ - トレーニングを開始します
