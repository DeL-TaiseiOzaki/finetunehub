tokenizer_config.json: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 46.4k/46.4k [00:00<00:00, 9.29MB/s]
tokenizer.model: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4.24M/4.24M [00:00<00:00, 11.0MB/s]
tokenizer.json: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 17.5M/17.5M [00:01<00:00, 10.5MB/s]
special_tokens_map.json: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 636/636 [00:00<00:00, 4.49MB/s]
config.json: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 856/856 [00:00<00:00, 5.20MB/s]
model.safetensors.index.json: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 39.1k/39.1k [00:00<00:00, 52.2MB/s]
Downloading shards:   0%|                                                                                                                                                        | 0/8 [00:00<?, ?it/s]







































































































































































































































Downloading shards:  12%|█████████████████▉                                                                                                                             | 1/8 [07:45<54:18, 465.55s/it]














































































































































































































































Downloading shards:  25%|███████████████████████████████████▊                                                                                                           | 2/8 [15:42<47:13, 472.25s/it]












































































































































































































































Downloading shards:  38%|█████████████████████████████████████████████████████▋                                                                                         | 3/8 [23:39<39:31, 474.25s/it]












































































































































































































































Downloading shards:  50%|███████████████████████████████████████████████████████████████████████▌                                                                       | 4/8 [31:33<31:36, 474.11s/it]













































































































































































































































Downloading shards:  62%|█████████████████████████████████████████████████████████████████████████████████████████▍                                                     | 5/8 [39:29<23:45, 475.07s/it]













































































































































































































































Downloading shards:  75%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                   | 6/8 [47:26<15:51, 475.64s/it]













































































































































































































































Downloading shards:  88%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                 | 7/8 [55:23<07:56, 476.01s/it]

















































































































Downloading shards: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [59:11<00:00, 443.99s/it]



Loading checkpoint shards: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:06<00:00,  1.15it/s]
generation_config.json: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 173/173 [00:00<00:00, 1.25MB/s]
Downloading readme: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3.70k/3.70k [00:00<00:00, 143kB/s]












































Downloading data: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 942M/942M [01:30<00:00, 10.3MB/s]
Generating train split: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 508426/508426 [00:11<00:00, 45853.75 examples/s]
Map (num_proc=4):   0%|                                                                                                                                              | 0/508426 [00:01<?, ? examples/s]
multiprocess.pool.RemoteTraceback:
"""
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/multiprocess/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/usr/local/lib/python3.10/dist-packages/datasets/utils/py_utils.py", line 678, in _write_generator_to_queue
    for i, result in enumerate(func(**kwargs)):
  File "/usr/local/lib/python3.10/dist-packages/datasets/arrow_dataset.py", line 3558, in _map_single
    batch = apply_function_on_filtered_inputs(
  File "/usr/local/lib/python3.10/dist-packages/datasets/arrow_dataset.py", line 3427, in apply_function_on_filtered_inputs
    processed_inputs = function(*fn_args, *additional_args, **fn_kwargs)
  File "/mnt/ozaki/finetunehub/scripts/data_processing.py", line 75, in generate_prompt
    formatted_text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)
  File "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py", line 1786, in apply_chat_template
    chat_template = self.get_chat_template(chat_template, tools)
  File "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py", line 2025, in get_chat_template
    raise ValueError(
ValueError: Cannot use apply_chat_template() because tokenizer.chat_template is not set and no template argument was passed! For information about writing templates and setting the tokenizer.chat_template attribute, please see the documentation at https://huggingface.co/docs/transformers/main/en/chat_templating
"""
The above exception was the direct cause of the following exception:
Traceback (most recent call last):
  File "/mnt/ozaki/finetunehub/scripts/main.py", line 74, in <module>
    main()
  File "/mnt/ozaki/finetunehub/scripts/main.py", line 64, in main
    train_dataset = load_and_prepare_datasets(config, tokenizer, logger)
  File "/mnt/ozaki/finetunehub/scripts/data_processing.py", line 94, in load_and_prepare_datasets
    train_dataset = train_dataset.map(
  File "/usr/local/lib/python3.10/dist-packages/datasets/arrow_dataset.py", line 602, in wrapper
    out: Union["Dataset", "DatasetDict"] = func(self, *args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/datasets/arrow_dataset.py", line 567, in wrapper
    out: Union["Dataset", "DatasetDict"] = func(self, *args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/datasets/arrow_dataset.py", line 3259, in map
    for rank, done, content in iflatmap_unordered(
  File "/usr/local/lib/python3.10/dist-packages/datasets/utils/py_utils.py", line 718, in iflatmap_unordered
    [async_result.get(timeout=0.05) for async_result in async_results]
  File "/usr/local/lib/python3.10/dist-packages/datasets/utils/py_utils.py", line 718, in <listcomp>
    [async_result.get(timeout=0.05) for async_result in async_results]
  File "/usr/local/lib/python3.10/dist-packages/multiprocess/pool.py", line 774, in get
    raise self._value
ValueError: Cannot use apply_chat_template() because tokenizer.chat_template is not set and no template argument was passed! For information about writing templates and setting the tokenizer.chat_template attribute, please see the documentation at https://huggingface.co/docs/transformers/main/en/chat_templating